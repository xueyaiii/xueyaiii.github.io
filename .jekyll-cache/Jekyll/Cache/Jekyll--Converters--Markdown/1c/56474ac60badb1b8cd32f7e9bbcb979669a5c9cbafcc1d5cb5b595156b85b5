I"XL<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

<h1 id="实现logistic回归">实现Logistic回归</h1>
<h2 id="原理">原理</h2>
<h3 id="概述">概述</h3>
<ul>
  <li>有标签分类算法</li>
  <li>主要思想：由现有数据对分类边界线进行分类</li>
</ul>

<h3 id="数学背景">数学背景</h3>
<h4 id="回归">回归</h4>
<p>用一条直线对已知的数据点进行拟合</p>
<h4 id="sigmoid函数">Sigmoid函数</h4>
<ul>
  <li>公式：
<script type="math/tex">\sigma(z)=\frac{1}{1+e^{-z}}</script></li>
  <li>$z$为0时，$\sigma(z)$为0.5，$z$为$+\infty$，$\sigma(z)$为1，$z$为$-\infty$，$\sigma(z)$为0</li>
  <li>如果横坐标刻度足够大，Sigmoid函数就像一个阶跃函数，可以达到分类的目的</li>
</ul>

<h4 id="引入logistic分类器">引入Logistic分类器</h4>
<ul>
  <li>在每个特征$x_{i}$上乘上一个回归系数$w_{i}$,相加得到$z$(<strong>拟合</strong>)，将$z$代入Sigmoid函数，任何大于 0.5 的数据被分入 1 类，小于 0.5 即被归入 0 类
<script type="math/tex">z=w_{0} x_{0}+w_{1} x_{1}+w_{2} x_{2}+\ldots+w_{n} x_{n}</script>
即：
<script type="math/tex">z=w^{T} x</script></li>
  <li>我们现在的目标是求解这些回归系数$w_{i}$</li>
</ul>

<h4 id="基于梯度上升法确定回归系数拟合">基于梯度上升法确定回归系数（拟合）</h4>
<ul>
  <li>设样本的类别标签为$y$，回归系数为$w$，样本矩阵为$x$，误差为$e$，步长为$alpha$。</li>
  <li>我们的目标是最小化误差$e^{T} e$(因为是列向量)反过来就是最大化$-e^{T} e$，为消去因子，此处最大化$-\frac{1}{2} e^{T} e$</li>
  <li>$-\frac{1}{2} e^{T} e=-\frac{1}{2}(x w-y)^{T}(x w-y)=f(w)$拆开来就是：$f(w)=-\frac{1}{2}\left(w^{T} x^{T}-y\right)(x w-y)=-\frac{1}{2}\left(w^{T} x^{T} x w-w^{T} x^{T} y-y^{T} x w+y^{T} y\right)$</li>
  <li>到这就可以用梯度上升算法，对求导可以得出$\frac{\partial f(w)}{\partial w}=x^{T} y-x^{T} x w=x^{T}(y-w x)=x^{T} e$</li>
  <li>更新回归系数的公式就是：$w=w+\alpha x^{T} e$</li>
</ul>

<h3 id="logistic-算法过程">Logistic 算法过程</h3>
<h4 id="logistic-回归算法">Logistic 回归算法</h4>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>初始化所有回归系数  
重复R次：  
    计算整个数据集梯度
    使用 步长乘以梯度 更新回归系数
返回回归系数
</code></pre></div></div>
<h4 id="logistic-回归-开发流程">Logistic 回归 开发流程</h4>
<p>收集数据
准备数据: 由于需要进行距离计算，因此要求数据类型为数值型。
分析数据
训练算法: 找到最佳的分类回归系数。
测试算法</p>
<h2 id="实例">实例</h2>
<h3 id="算法">算法</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="c1"># 解析数据
</span><span class="k">def</span> <span class="nf">loadDataSet</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
    <span class="c1"># dataMat为原始数据， labelMat为原始数据的标签
</span>    <span class="n">dataMat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labelMat</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">fr</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fr</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">lineArr</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lineArr</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>    <span class="c1"># 这里如果就一个空的元素，则跳过本次循环
</span>        <span class="c1"># 为了方便计算，我们将 X0 的值设为 1.0 ，也就是在每一行的开头添加一个 1.0 作为 X0
</span>        <span class="n">dataMat</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">lineArr</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">lineArr</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
        <span class="n">labelMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">lineArr</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">dataMat</span><span class="p">,</span> <span class="n">labelMat</span>

<span class="c1"># sigmoid跳跃函数
</span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">inX</span><span class="p">):</span>
    <span class="c1"># return 1.0 / (1 + exp(-inX))
</span>
    <span class="c1"># Tanh是Sigmoid的变形，与 sigmoid 不同的是，tanh 是0均值的。因此，实际应用中，tanh 会比 sigmoid 更好。
</span>    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">inX</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># 随机梯度下降算法（随机化）
</span><span class="k">def</span> <span class="nf">stocGradAscent</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="n">numIter</span><span class="o">=</span><span class="mi">150</span><span class="p">):</span>
    <span class="s">'''
    Desc:
        改进版的随机梯度下降，使用随机的一个样本来更新回归系数
    Args:
        dataMatrix -- 输入数据的数据特征（除去最后一列数据）
        classLabels -- 输入数据的类别标签（最后一列数据）
        numIter=150 --  迭代次数
    Returns:
        weights -- 得到的最佳回归系数
    '''</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># 创建与列数相同的矩阵的系数矩阵，所有的元素都是1
</span>    <span class="c1"># 随机梯度, 循环150,观察是否收敛
</span>    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numIter</span><span class="p">):</span>
        <span class="c1"># [0, 1, 2 .. m-1]
</span>        <span class="n">dataIndex</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="c1"># i和j的不断增大，导致alpha的值不断减少，但是不为0
</span>            <span class="n">alpha</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">/</span> <span class="p">(</span>
                <span class="mf">1.0</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="n">i</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mf">0.0001</span>  <span class="c1"># alpha 会随着迭代不断减小，但永远不会减小到0，因为后边还有一个常数项0.0001
</span>            <span class="c1"># 随机产生一个 0～len()之间的一个值
</span>            <span class="c1"># random.uniform(x, y) 方法将随机生成下一个实数，它在[x,y]范围内,x是这个范围内的最小值，y是这个范围内的最大值。
</span>            <span class="n">randIndex</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataIndex</span><span class="p">)))</span>
            <span class="c1"># sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn
</span>            <span class="n">h</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">[</span><span class="n">dataIndex</span><span class="p">[</span><span class="n">randIndex</span><span class="p">]]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">))</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">classLabels</span><span class="p">[</span><span class="n">dataIndex</span><span class="p">[</span><span class="n">randIndex</span><span class="p">]]</span> <span class="o">-</span> <span class="n">h</span>
            <span class="c1"># print weights, '__h=%s' % h, '__'*20, alpha, '__'*20, error, '__'*20, dataMatrix[randIndex]
</span>            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dataMatrix</span><span class="p">[</span><span class="n">dataIndex</span><span class="p">[</span><span class="n">randIndex</span><span class="p">]]</span>
            <span class="k">del</span> <span class="p">(</span><span class="n">dataIndex</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">weights</span>

<span class="c1"># 可视化展示
</span><span class="k">def</span> <span class="nf">plotBestFit</span><span class="p">(</span><span class="n">dataArr</span><span class="p">,</span> <span class="n">labelMat</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="s">'''
        Desc:
            将我们得到的数据可视化展示出来
        Args:
            dataArr:样本数据的特征
            labelMat:样本数据的类别标签，即目标变量
            weights:回归系数
        Returns:
            None
    '''</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">dataArr</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xcord1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ycord1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">xcord2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ycord2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">labelMat</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">xcord1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">ycord1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xcord2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">ycord2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xcord1</span><span class="p">,</span> <span class="n">ycord1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'s'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xcord2</span><span class="p">,</span> <span class="n">ycord2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'green'</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="s">"""
    y的由来
    dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])
    w0*x0+w1*x1+w2*x2=f(x)
    x0最开始就设置为1叻， x2就是我们画图的y值，而f(x)被我们磨合误差给算到w0,w1,w2身上去了
    所以： w0+w1*x+w2*y=0 =&gt; y = (-w0-w1*x)/w2   
    """</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'X'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Y'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">simpleTest</span><span class="p">():</span>
    <span class="c1"># 1.收集并准备数据
</span>    <span class="n">dataMat</span><span class="p">,</span> <span class="n">labelMat</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">(</span><span class="s">"TestSet.txt"</span><span class="p">)</span>

    <span class="c1"># 2.训练模型，  f(x)=a1*x1+b2*x2+..+nn*xn中 (a1,b2, .., nn).T的矩阵值
</span>    <span class="c1"># 因为数组没有是复制n份， array的乘法就是乘法
</span>    <span class="n">dataArr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataMat</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">stocGradAscent</span><span class="p">(</span><span class="n">dataArr</span><span class="p">,</span> <span class="n">labelMat</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="c1"># 数据可视化
</span>    <span class="n">plotBestFit</span><span class="p">(</span><span class="n">dataArr</span><span class="p">,</span> <span class="n">labelMat</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">simpleTest</span><span class="p">()</span>
</code></pre></div></div>
<h3 id="运行环境">运行环境</h3>
<p>Windows10+Anaconda Spyder（Python 3.5)</p>
<h3 id="运行结果">运行结果</h3>
<p><img src="/image/Logistic回归.PNG" alt="运行结果" /></p>
:ET